{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "4.bert-accurate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moUpmPbk0BHp",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/huseinzol05/NLP-Models-Tensorflow/tree/master/spelling-correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEnXDDLEAG10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ekphrasis\n",
        "!apt install enchant\n",
        "!pip install pyenchant\n",
        "!apt-get install myspell-pt-br\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip\n",
        "# data from https://github.com/cbaziotis/ekphrasis/blob/master/ekphrasis/utils/helpers.py\n",
        "# reuploaded to husein's S3\n",
        "!wget https://malaya-dataset.s3-ap-southeast-1.amazonaws.com/counts_1grams.txt\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3CHCxnRxCQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9kvn54xCRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('counts_1grams.txt') as fopen:\n",
        "    f = fopen.read().split('\\n')[:-1]\n",
        "    \n",
        "words = {}\n",
        "for l in f:\n",
        "    w, c = l.split('\\t')\n",
        "    c = int(c)\n",
        "    words[w] = c + words.get(w, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9UC8TnExCRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# original from https://github.com/cbaziotis/ekphrasis/blob/master/ekphrasis/classes/spellcorrect.py\n",
        "# improved it\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "class SpellCorrector:\n",
        "    \"\"\"\n",
        "    The SpellCorrector extends the functionality of the Peter Norvig's\n",
        "    spell-corrector in http://norvig.com/spell-correct.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        :param corpus: the statistics from which corpus to use for the spell correction.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.WORDS = words\n",
        "        self.N = sum(self.WORDS.values())\n",
        "        \n",
        "    @staticmethod\n",
        "    def tokens(text):\n",
        "        return REGEX_TOKEN.findall(text.lower())\n",
        "\n",
        "    def P(self, word):\n",
        "        \"\"\"\n",
        "        Probability of `word`.\n",
        "        \"\"\"\n",
        "        return self.WORDS[word] / self.N\n",
        "\n",
        "    def most_probable(self, words):\n",
        "        _known = self.known(words)\n",
        "        if _known:\n",
        "            return max(_known, key=self.P)\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    @staticmethod\n",
        "    def edit_step(word):\n",
        "        \"\"\"\n",
        "        All edits that are one edit away from `word`.\n",
        "        \"\"\"\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "    def edits2(self, word):\n",
        "        \"\"\"\n",
        "        All edits that are two edits away from `word`.\n",
        "        \"\"\"\n",
        "        return (e2 for e1 in self.edit_step(word)\n",
        "                for e2 in self.edit_step(e1))\n",
        "\n",
        "    def known(self, words):\n",
        "        \"\"\"\n",
        "        The subset of `words` that appear in the dictionary of WORDS.\n",
        "        \"\"\"\n",
        "        return set(w for w in words if w in self.WORDS)\n",
        "\n",
        "    def edit_candidates(self, word, assume_wrong=False, fast=True):\n",
        "        \"\"\"\n",
        "        Generate possible spelling corrections for w!pip install bert-tensorfloword.\n",
        "        \"\"\"\n",
        "\n",
        "        if fast:\n",
        "            ttt = self.known(self.edit_step(word)) or {word}\n",
        "        else:\n",
        "            ttt = self.known(self.edit_step(word)) or self.known(self.edits2(word)) or {word}\n",
        "        \n",
        "        ttt = self.known([word]) | ttt\n",
        "        return list(ttt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tQWUiGzxCRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrector = SpellCorrector()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk6qe9SA_2_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "dd227579-d361-4ef0-f40c-577d46251db9"
      },
      "source": [
        "# modificar para todas as palavras\n",
        "from enchant import DictWithPWL\n",
        "from enchant.checker import SpellChecker\n",
        "from copy import deepcopy\n",
        "my_dict = DictWithPWL(\"en_US\", \"mywords.txt\")\n",
        "my_checker = SpellChecker(my_dict)\n",
        "text = \"This is sme sample txt with erors.\"\n",
        "my_checker.set_text(text)\n",
        "text_mask = deepcopy(text)\n",
        "for error in my_checker:\n",
        "  possible_states = corrector.edit_candidates(error.word)\n",
        "  print(possible_states)\n",
        "  text_mask = text_mask.replace(erros[-1], '**mask**')\n",
        "\n",
        "text_mask"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ame', 'zme', 'smr', 'smye', 'smd', 'sze', 'smb', 'smu', 'se', 'syme', 'bme', 'bsme', 'smq', 'yme', 'some', 'vme', 'jsme', 'smz', 'cme', 'rme', 'sbe', 'smet', 'sge', 'smei', 'pme', 'smj', 'smes', 'soe', 'ime', 'nme', 'sye', 'ske', 'lme', 'usme', 'sce', 'smg', 'smo', 'mse', 'smn', 'esme', 'sje', 'dme', 'smw', 'smex', 'tme', 'smm', 'isme', 'smh', 'sse', 'sxe', 'sm', 'sem', 'smed', 'she', 'gme', 'see', 'smee', 'mme', 'sume', 'smep', 'me', 'snme', 'smy', 'osme', 'smx', 'smec', 'sie', 'sme', 'smv', 'smer', 'xme', 'sue', 'smew', 'smae', 'fme', 'smp', 'sne', 'sqe', 'same', 'rsme', 'jme', 'csme', 'smle', 'ome', 'smoe', 'smf', 'ste', 'sma', 'sde', 'wme', 'sml', 'sime', 'eme', 'asme', 'sbme', 'smk', 'seme', 'smi', 'ume', 'spe', 'swe', 'hme', 'sle', 'smej', 'sre', 'smc', 'dsme', 'smt', 'smeg', 'kme', 'sms', 'sfe', 'sve', 'ssme', 'spme', 'sae', 'msme']\n",
            "['txf', 'tgt', 'txp', 'text', 'tjt', 'fxt', 'tht', 'tpt', 'axt', 'tst', 'cxt', 'tat', 'txo', 'tet', 'txx', 'tot', 'ext', 'txg', 'txy', 'txi', 'tx', 'tut', 'bxt', 'ktxt', 'oxt', 'txa', 'txc', 'lxt', 'txu', 'gxt', 'trt', 'txd', 'txe', 'txn', 'tmt', 'etxt', 'sxt', 'tnt', 'twt', 'dxt', 'txt', 'txk', 'tbt', 'tkt', 'ttt', 'txm', 'txl', 'tt', 'tdt', 'ttx', 'tit', 'tlt', 'xt', 'tvt', 'txs', 'taxt', 'tyt', 'txw', 'tct', 'mxt', 'nxt', 'tft']\n",
            "['eros', 'erols', 'erora', 'errors', 'rors', 'erros', 'errs', 'eroms']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is sme sample txt with **mask**.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4lRZEE8Bdf0",
        "colab": {}
      },
      "source": [
        "#possible_states = corrector.edit_candidates(erros[0])\n",
        "#possible_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Rc7sdfxCRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BERT_VOCAB = 'uncased_L-12_H-768_A-12/vocab.txt'\n",
        "BERT_INIT_CHKPNT = 'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
        "BERT_CONFIG = 'uncased_L-12_H-768_A-12/bert_config.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9aVPZixCRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "from bert import modeling\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsiIoCPPxCRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenization.validate_case_matches_checkpoint(True,BERT_INIT_CHKPNT)\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=BERT_VOCAB, do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWFRWVnhxCRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "074e8376-f95b-43aa-d7ae-a694a4c3d98b"
      },
      "source": [
        "#text = 'scientist suggests eting berger can lead to obesity'\n",
        "#text_mask = text.replace('eting', '**mask**')\n",
        "#text_mask"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'scientist suggests **mask** berger can lead to obesity'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbrka-B1xCRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_masked_ids(tokens, mask_ind):\n",
        "    masked_tokens = tokens[:]\n",
        "    masked_tokens[mask_ind] = \"[MASK]\"\n",
        "    masked_tokens = [\"[CLS]\"] + masked_tokens + [\"[SEP]\"]\n",
        "    masked_ids = tokenizer.convert_tokens_to_ids(masked_tokens)\n",
        "    return masked_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIuFXgUuxCRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DHNE7t7xCRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "    def __init__(\n",
        "        self,\n",
        "    ):\n",
        "        self.X = tf.placeholder(tf.int32, [None, None])\n",
        "        \n",
        "        model = modeling.BertModel(\n",
        "            config=bert_config,\n",
        "            is_training=False,\n",
        "            input_ids=self.X,\n",
        "            use_one_hot_embeddings=False)\n",
        "        \n",
        "        output_layer = model.get_sequence_output()\n",
        "        embedding = model.get_embedding_table()\n",
        "        \n",
        "        with tf.variable_scope('cls/predictions'):\n",
        "            with tf.variable_scope('transform'):\n",
        "                input_tensor = tf.layers.dense(\n",
        "                    output_layer,\n",
        "                    units = bert_config.hidden_size,\n",
        "                    activation = modeling.get_activation(bert_config.hidden_act),\n",
        "                    kernel_initializer = modeling.create_initializer(\n",
        "                        bert_config.initializer_range\n",
        "                    ),\n",
        "                )\n",
        "                input_tensor = modeling.layer_norm(input_tensor)\n",
        "            \n",
        "            output_bias = tf.get_variable(\n",
        "            'output_bias',\n",
        "            shape = [bert_config.vocab_size],\n",
        "            initializer = tf.zeros_initializer(),\n",
        "            )\n",
        "            logits = tf.matmul(input_tensor, embedding, transpose_b = True)\n",
        "            self.logits = tf.nn.bias_add(logits, output_bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7owTpoBJxCRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f1428198-7b40-49cc-bb7c-c7634fcd3d15"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "model = Model()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "var_lists = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'bert')"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FJMRO5yxCRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6deec2e3-0a3b-4cd3-848d-b2180ae30f5a"
      },
      "source": [
        "cls = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'cls')\n",
        "cls"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/output_bias:0' shape=(30522,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_94UTUcnxCRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6dc1ecd-a637-4b9f-b322-46ef2f0e3b7f"
      },
      "source": [
        "saver = tf.train.Saver(var_list = var_lists + cls)\n",
        "saver.restore(sess, BERT_INIT_CHKPNT)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from uncased_L-12_H-768_A-12/bert_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdb37AstxCRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a828cb17-a1c3-4ad6-ba66-e241dca7b633"
      },
      "source": [
        "replaced_masks = [text_mask.replace('**mask**', state) for state in possible_states]\n",
        "replaced_masks"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This is sme sample txt with eros.',\n",
              " 'This is sme sample txt with erols.',\n",
              " 'This is sme sample txt with erora.',\n",
              " 'This is sme sample txt with errors.',\n",
              " 'This is sme sample txt with rors.',\n",
              " 'This is sme sample txt with erros.',\n",
              " 'This is sme sample txt with errs.',\n",
              " 'This is sme sample txt with eroms.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf5-5u1sxCRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5d18cc53-4d38-43dc-b3c7-f13a427da05e"
      },
      "source": [
        "tokens = tokenizer.tokenize(replaced_masks[0])\n",
        "input_ids = [tokens_to_masked_ids(tokens, i) for i in range(len(tokens))]\n",
        "input_ids"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[101, 103, 2003, 15488, 2063, 7099, 19067, 2102, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 103, 15488, 2063, 7099, 19067, 2102, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 103, 2063, 7099, 19067, 2102, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 103, 7099, 19067, 2102, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 103, 19067, 2102, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 7099, 103, 2102, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 7099, 19067, 103, 2007, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 7099, 19067, 2102, 103, 9413, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 7099, 19067, 2102, 2007, 103, 2891, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 7099, 19067, 2102, 2007, 9413, 103, 1012, 102],\n",
              " [101, 2023, 2003, 15488, 2063, 7099, 19067, 2102, 2007, 9413, 2891, 103, 102]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m449L5A8xCRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "145ca00b-04f9-4964-a5e9-e9e92ba76737"
      },
      "source": [
        "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens_ids"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2023, 2003, 15488, 2063, 7099, 19067, 2102, 2007, 9413, 2891, 1012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS-VXc_cxCRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_ids(mask):\n",
        "    tokens = tokenizer.tokenize(mask)\n",
        "    input_ids = [tokens_to_masked_ids(tokens, i) for i in range(len(tokens))]\n",
        "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return tokens, input_ids, tokens_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX1sWoSCxCRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = [generate_ids(mask) for mask in replaced_masks]\n",
        "tokens, input_ids, tokens_ids = list(zip(*ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faNvlD5UxCRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices, ids = [], []\n",
        "for i in range(len(input_ids)):\n",
        "    indices.extend([i] * len(input_ids[i]))\n",
        "    ids.extend(input_ids[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLpoM_LSxCR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ec03ca2-085c-4066-f75c-8326d5844ab0"
      },
      "source": [
        "ids[0]"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 103, 2003, 15488, 2063, 7099, 19067, 2102, 2007, 9413, 2891, 1012, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXhw9E5gxCR3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57ad5812-a921-4877-a98a-8625a5046f16"
      },
      "source": [
        "masked_padded = tf.keras.preprocessing.sequence.pad_sequences(ids,padding='post')\n",
        "masked_padded.shape"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja58NbA1xCR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9781be0-dad4-4b0d-e81a-45e03513bc07"
      },
      "source": [
        "preds = sess.run(tf.nn.log_softmax(model.logits), feed_dict = {model.X: masked_padded})\n",
        "preds.shape"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 13, 30522)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycPI5BqfxCR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c3548ab3-7082-4916-8b02-c354af7b25ff"
      },
      "source": [
        "indices = np.array(indices)\n",
        "scores = []\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    filter_preds = preds[indices == i]\n",
        "    total = np.sum([filter_preds[k, k + 1, x] for k, x in enumerate(tokens_ids[i])])\n",
        "    scores.append(total)\n",
        "    \n",
        "scores"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-49.164173,\n",
              " -58.264732,\n",
              " -56.929756,\n",
              " -45.283386,\n",
              " -55.229176,\n",
              " -55.554077,\n",
              " -48.925648,\n",
              " -54.8601]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpAzsCVsxCR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51f3eda6-6272-454c-9e16-97df0b3c5f98"
      },
      "source": [
        "prob_scores = np.array(scores) / np.sum(scores)\n",
        "prob_scores"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11589555, 0.13734846, 0.1342015 , 0.1067473 , 0.13019268,\n",
              "       0.13095857, 0.11533327, 0.12932265], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7t4fQAxCR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = list(zip(possible_states, prob_scores))\n",
        "probs.sort(key = lambda x: x[1])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrx8tNlJ_bzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected = text_mask.replace('**mask**', probs[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIKySSm_iRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "158e0665-6856-436c-c3a0-89fd9aae64f7"
      },
      "source": [
        "corrected"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is sme sample txt with errors.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "4.bert-accurate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moUpmPbk0BHp",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/huseinzol05/NLP-Models-Tensorflow/tree/master/spelling-correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssgIj1ptxCQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "50a7f2bd-8167-45c4-f1ea-2252a3ec60da"
      },
      "source": [
        "# data from https://github.com/cbaziotis/ekphrasis/blob/master/ekphrasis/utils/helpers.py\n",
        "# reuploaded to husein's S3\n",
        "!wget https://malaya-dataset.s3-ap-southeast-1.amazonaws.com/counts_1grams.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-21 11:04:17--  https://malaya-dataset.s3-ap-southeast-1.amazonaws.com/counts_1grams.txt\n",
            "Resolving malaya-dataset.s3-ap-southeast-1.amazonaws.com (malaya-dataset.s3-ap-southeast-1.amazonaws.com)... 52.219.48.47\n",
            "Connecting to malaya-dataset.s3-ap-southeast-1.amazonaws.com (malaya-dataset.s3-ap-southeast-1.amazonaws.com)|52.219.48.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9535647 (9.1M) [text/plain]\n",
            "Saving to: ‘counts_1grams.txt’\n",
            "\n",
            "counts_1grams.txt   100%[===================>]   9.09M  3.41MB/s    in 2.7s    \n",
            "\n",
            "2020-01-21 11:04:21 (3.41 MB/s) - ‘counts_1grams.txt’ saved [9535647/9535647]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3CHCxnRxCQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9kvn54xCRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('counts_1grams.txt') as fopen:\n",
        "    f = fopen.read().split('\\n')[:-1]\n",
        "    \n",
        "words = {}\n",
        "for l in f:\n",
        "    w, c = l.split('\\t')\n",
        "    c = int(c)\n",
        "    words[w] = c + words.get(w, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q6FMQj3eAn",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/cbaziotis/ekphrasis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cXc4wWf3bRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ekphrasis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9UC8TnExCRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# original from https://github.com/cbaziotis/ekphrasis/blob/master/ekphrasis/classes/spellcorrect.py\n",
        "# improved it\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "class SpellCorrector:\n",
        "    \"\"\"\n",
        "    The SpellCorrector extends the functionality of the Peter Norvig's\n",
        "    spell-corrector in http://norvig.com/spell-correct.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        :param corpus: the statistics from which corpus to use for the spell correction.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.WORDS = words\n",
        "        self.N = sum(self.WORDS.values())\n",
        "        \n",
        "    @staticmethod\n",
        "    def tokens(text):\n",
        "        return REGEX_TOKEN.findall(text.lower())\n",
        "\n",
        "    def P(self, word):\n",
        "        \"\"\"\n",
        "        Probability of `word`.\n",
        "        \"\"\"\n",
        "        return self.WORDS[word] / self.N\n",
        "\n",
        "    def most_probable(self, words):\n",
        "        _known = self.known(words)\n",
        "        if _known:\n",
        "            return max(_known, key=self.P)\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    @staticmethod\n",
        "    def edit_step(word):\n",
        "        \"\"\"\n",
        "        All edits that are one edit away from `word`.\n",
        "        \"\"\"\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "    def edits2(self, word):\n",
        "        \"\"\"\n",
        "        All edits that are two edits away from `word`.\n",
        "        \"\"\"\n",
        "        return (e2 for e1 in self.edit_step(word)\n",
        "                for e2 in self.edit_step(e1))\n",
        "\n",
        "    def known(self, words):\n",
        "        \"\"\"\n",
        "        The subset of `words` that appear in the dictionary of WORDS.\n",
        "        \"\"\"\n",
        "        return set(w for w in words if w in self.WORDS)\n",
        "\n",
        "    def edit_candidates(self, word, assume_wrong=False, fast=True):\n",
        "        \"\"\"\n",
        "        Generate possible spelling corrections for word.\n",
        "        \"\"\"\n",
        "\n",
        "        if fast:\n",
        "            ttt = self.known(self.edit_step(word)) or {word}\n",
        "        else:\n",
        "            ttt = self.known(self.edit_step(word)) or self.known(self.edits2(word)) or {word}\n",
        "        \n",
        "        ttt = self.known([word]) | ttt\n",
        "        return list(ttt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tQWUiGzxCRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrector = SpellCorrector()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spE5Nb80xCRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "42eaa118-7653-4fcd-de6b-668565ecee04"
      },
      "source": [
        "possible_states = corrector.edit_candidates('eting')\n",
        "possible_states"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eing',\n",
              " 'reting',\n",
              " 'ering',\n",
              " 'epting',\n",
              " 'etling',\n",
              " 'eling',\n",
              " 'meting',\n",
              " 'enting',\n",
              " 'eying',\n",
              " 'edting',\n",
              " 'ewing',\n",
              " 'elting',\n",
              " 'ting',\n",
              " 'etang',\n",
              " 'eating',\n",
              " 'kting',\n",
              " 'sting',\n",
              " 'eking',\n",
              " 'etin',\n",
              " 'beting',\n",
              " 'eting',\n",
              " 'geting',\n",
              " 'ating',\n",
              " 'ebing',\n",
              " 'etting']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMe3vyIAxCRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Rc7sdfxCRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BERT_VOCAB = 'uncased_L-12_H-768_A-12/vocab.txt'\n",
        "BERT_INIT_CHKPNT = 'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
        "BERT_CONFIG = 'uncased_L-12_H-768_A-12/bert_config.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bctaYNOQx_II",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bef0a866-b324-4773-c993-b7c14a65c69e"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 27.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9aVPZixCRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "05c14e0a-7f9f-4b9b-d418-3cc560d278c2"
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "from bert import modeling\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsiIoCPPxCRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f0e79237-0659-495e-c058-d37f86f2e811"
      },
      "source": [
        "tokenization.validate_case_matches_checkpoint(True,BERT_INIT_CHKPNT)\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=BERT_VOCAB, do_lower_case=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWFRWVnhxCRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "074e8376-f95b-43aa-d7ae-a694a4c3d98b"
      },
      "source": [
        "text = 'scientist suggests eting berger can lead to obesity'\n",
        "text_mask = text.replace('eting', '**mask**')\n",
        "text_mask"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'scientist suggests **mask** berger can lead to obesity'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbrka-B1xCRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_masked_ids(tokens, mask_ind):\n",
        "    masked_tokens = tokens[:]\n",
        "    masked_tokens[mask_ind] = \"[MASK]\"\n",
        "    masked_tokens = [\"[CLS]\"] + masked_tokens + [\"[SEP]\"]\n",
        "    masked_ids = tokenizer.convert_tokens_to_ids(masked_tokens)\n",
        "    return masked_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIuFXgUuxCRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DHNE7t7xCRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "    def __init__(\n",
        "        self,\n",
        "    ):\n",
        "        self.X = tf.placeholder(tf.int32, [None, None])\n",
        "        \n",
        "        model = modeling.BertModel(\n",
        "            config=bert_config,\n",
        "            is_training=False,\n",
        "            input_ids=self.X,\n",
        "            use_one_hot_embeddings=False)\n",
        "        \n",
        "        output_layer = model.get_sequence_output()\n",
        "        embedding = model.get_embedding_table()\n",
        "        \n",
        "        with tf.variable_scope('cls/predictions'):\n",
        "            with tf.variable_scope('transform'):\n",
        "                input_tensor = tf.layers.dense(\n",
        "                    output_layer,\n",
        "                    units = bert_config.hidden_size,\n",
        "                    activation = modeling.get_activation(bert_config.hidden_act),\n",
        "                    kernel_initializer = modeling.create_initializer(\n",
        "                        bert_config.initializer_range\n",
        "                    ),\n",
        "                )\n",
        "                input_tensor = modeling.layer_norm(input_tensor)\n",
        "            \n",
        "            output_bias = tf.get_variable(\n",
        "            'output_bias',\n",
        "            shape = [bert_config.vocab_size],\n",
        "            initializer = tf.zeros_initializer(),\n",
        "            )\n",
        "            logits = tf.matmul(input_tensor, embedding, transpose_b = True)\n",
        "            self.logits = tf.nn.bias_add(logits, output_bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7owTpoBJxCRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c3d4edf5-786c-4654-d5fa-d608847e9701"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "model = Model()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "var_lists = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'bert')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FJMRO5yxCRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6865e01a-eb35-499d-d71e-fc26a4be5467"
      },
      "source": [
        "cls = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'cls')\n",
        "cls"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
              " <tf.Variable 'cls/predictions/output_bias:0' shape=(30522,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_94UTUcnxCRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acc8b63e-c086-4d77-c176-c9b18405c6dc"
      },
      "source": [
        "saver = tf.train.Saver(var_list = var_lists + cls)\n",
        "saver.restore(sess, BERT_INIT_CHKPNT)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from uncased_L-12_H-768_A-12/bert_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdb37AstxCRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6c48053a-b35f-49f2-c2bb-8b9471c436c3"
      },
      "source": [
        "replaced_masks = [text_mask.replace('**mask**', state) for state in possible_states]\n",
        "replaced_masks"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scientist suggests eing berger can lead to obesity',\n",
              " 'scientist suggests reting berger can lead to obesity',\n",
              " 'scientist suggests ering berger can lead to obesity',\n",
              " 'scientist suggests epting berger can lead to obesity',\n",
              " 'scientist suggests etling berger can lead to obesity',\n",
              " 'scientist suggests eling berger can lead to obesity',\n",
              " 'scientist suggests meting berger can lead to obesity',\n",
              " 'scientist suggests enting berger can lead to obesity',\n",
              " 'scientist suggests eying berger can lead to obesity',\n",
              " 'scientist suggests edting berger can lead to obesity',\n",
              " 'scientist suggests ewing berger can lead to obesity',\n",
              " 'scientist suggests elting berger can lead to obesity',\n",
              " 'scientist suggests ting berger can lead to obesity',\n",
              " 'scientist suggests etang berger can lead to obesity',\n",
              " 'scientist suggests eating berger can lead to obesity',\n",
              " 'scientist suggests kting berger can lead to obesity',\n",
              " 'scientist suggests sting berger can lead to obesity',\n",
              " 'scientist suggests eking berger can lead to obesity',\n",
              " 'scientist suggests etin berger can lead to obesity',\n",
              " 'scientist suggests beting berger can lead to obesity',\n",
              " 'scientist suggests eting berger can lead to obesity',\n",
              " 'scientist suggests geting berger can lead to obesity',\n",
              " 'scientist suggests ating berger can lead to obesity',\n",
              " 'scientist suggests ebing berger can lead to obesity',\n",
              " 'scientist suggests etting berger can lead to obesity']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf5-5u1sxCRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "616247b4-2d23-4752-9b0b-2b31b3fa0e37"
      },
      "source": [
        "tokens = tokenizer.tokenize(replaced_masks[0])\n",
        "input_ids = [tokens_to_masked_ids(tokens, i) for i in range(len(tokens))]\n",
        "input_ids"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[101, 103, 6083, 16417, 2290, 16758, 2064, 2599, 2000, 24552, 102],\n",
              " [101, 7155, 103, 16417, 2290, 16758, 2064, 2599, 2000, 24552, 102],\n",
              " [101, 7155, 6083, 103, 2290, 16758, 2064, 2599, 2000, 24552, 102],\n",
              " [101, 7155, 6083, 16417, 103, 16758, 2064, 2599, 2000, 24552, 102],\n",
              " [101, 7155, 6083, 16417, 2290, 103, 2064, 2599, 2000, 24552, 102],\n",
              " [101, 7155, 6083, 16417, 2290, 16758, 103, 2599, 2000, 24552, 102],\n",
              " [101, 7155, 6083, 16417, 2290, 16758, 2064, 103, 2000, 24552, 102],\n",
              " [101, 7155, 6083, 16417, 2290, 16758, 2064, 2599, 103, 24552, 102],\n",
              " [101, 7155, 6083, 16417, 2290, 16758, 2064, 2599, 2000, 103, 102]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m449L5A8xCRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf3b245b-753e-4ea9-ae4b-82e11ef02ebf"
      },
      "source": [
        "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens_ids"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7155, 6083, 16417, 2290, 16758, 2064, 2599, 2000, 24552]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTeE4EJcydaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score(mask):\n",
        "    tokens = tokenizer.tokenize(mask)\n",
        "    input_ids = [tokens_to_masked_ids(tokens, i) for i in range(len(tokens))]\n",
        "    preds = sess.run(tf.nn.softmax(model.logits), feed_dict = {model.X: input_ids})\n",
        "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return np.prod([preds[i, i + 1, x] for i, x in enumerate(tokens_ids)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS-VXc_cxCRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_ids(mask):\n",
        "    tokens = tokenizer.tokenize(mask)\n",
        "    input_ids = [tokens_to_masked_ids(tokens, i) for i in range(len(tokens))]\n",
        "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return tokens, input_ids, tokens_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX1sWoSCxCRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = [generate_ids(mask) for mask in replaced_masks]\n",
        "tokens, input_ids, tokens_ids = list(zip(*ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faNvlD5UxCRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices, ids = [], []\n",
        "for i in range(len(input_ids)):\n",
        "    indices.extend([i] * len(input_ids[i]))\n",
        "    ids.extend(input_ids[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLpoM_LSxCR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d6d60a2-07eb-405c-bd01-9e58548f76bf"
      },
      "source": [
        "ids[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 103, 6083, 16417, 2290, 16758, 2064, 2599, 2000, 24552, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXhw9E5gxCR3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acefc157-13a5-4fd9-c1a0-a09fbedd00ef"
      },
      "source": [
        "masked_padded = tf.keras.preprocessing.sequence.pad_sequences(ids,padding='post')\n",
        "masked_padded.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja58NbA1xCR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0a1718b-4989-4436-9160-36b3992ba02a"
      },
      "source": [
        "preds = sess.run(tf.nn.log_softmax(model.logits), feed_dict = {model.X: masked_padded})\n",
        "preds.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221, 11, 30522)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycPI5BqfxCR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "b577c4ff-70d5-4a0c-eb13-e250b505c0d4"
      },
      "source": [
        "indices = np.array(indices)\n",
        "scores = []\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    filter_preds = preds[indices == i]\n",
        "    total = np.sum([filter_preds[k, k + 1, x] for k, x in enumerate(tokens_ids[i])])\n",
        "    scores.append(total)\n",
        "    \n",
        "scores"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-65.73369,\n",
              " -63.164936,\n",
              " -62.57653,\n",
              " -73.19431,\n",
              " -73.97393,\n",
              " -63.397663,\n",
              " -60.225082,\n",
              " -62.37426,\n",
              " -61.714867,\n",
              " -70.874214,\n",
              " -62.557587,\n",
              " -67.8916,\n",
              " -67.46682,\n",
              " -62.33689,\n",
              " -45.84125,\n",
              " -73.77844,\n",
              " -63.562042,\n",
              " -57.582092,\n",
              " -67.74833,\n",
              " -69.86494,\n",
              " -71.33391,\n",
              " -70.08538,\n",
              " -67.535416,\n",
              " -73.42106,\n",
              " -67.14624]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpAzsCVsxCR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bed8904b-6485-40d0-cbf6-31a40c8d486f"
      },
      "source": [
        "prob_scores = np.array(scores) / np.sum(scores)\n",
        "prob_scores"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03995042, 0.03838924, 0.03803163, 0.04448471, 0.04495853,\n",
              "       0.03853068, 0.0366025 , 0.03790869, 0.03750794, 0.04307464,\n",
              "       0.03802011, 0.04126192, 0.04100376, 0.03788598, 0.02786056,\n",
              "       0.04483972, 0.03863058, 0.0349962 , 0.04117485, 0.04246124,\n",
              "       0.04335402, 0.04259522, 0.04104545, 0.04462251, 0.04080892],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7t4fQAxCR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "ebd988c1-c5ef-4a3a-f25e-e3767a02450f"
      },
      "source": [
        "probs = list(zip(possible_states, prob_scores))\n",
        "probs.sort(key = lambda x: x[1])  \n",
        "probs"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('eating', 0.027860561),\n",
              " ('eking', 0.034996197),\n",
              " ('meting', 0.036602505),\n",
              " ('eying', 0.03750794),\n",
              " ('etang', 0.037885983),\n",
              " ('enting', 0.037908692),\n",
              " ('ewing', 0.03802011),\n",
              " ('ering', 0.038031626),\n",
              " ('reting', 0.038389236),\n",
              " ('eling', 0.038530678),\n",
              " ('sting', 0.038630582),\n",
              " ('eing', 0.039950423),\n",
              " ('etting', 0.04080892),\n",
              " ('ting', 0.041003756),\n",
              " ('ating', 0.041045446),\n",
              " ('etin', 0.041174848),\n",
              " ('elting', 0.041261923),\n",
              " ('beting', 0.04246124),\n",
              " ('geting', 0.042595215),\n",
              " ('edting', 0.04307464),\n",
              " ('eting', 0.043354023),\n",
              " ('epting', 0.04448471),\n",
              " ('ebing', 0.044622514),\n",
              " ('kting', 0.044839717),\n",
              " ('etling', 0.044958528)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}
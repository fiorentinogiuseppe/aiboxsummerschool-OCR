{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "f1_measure_text.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BtFoWGD-6w0u",
        "DAAdV7JJ6yps",
        "s5wfzXPL61qa",
        "yNTv7uUd6zvx",
        "kwhI9ToYYSSO",
        "xFe2XawZ7OT5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtFoWGD-6w0u",
        "colab_type": "text"
      },
      "source": [
        "# Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCBLjYISyORl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip drive*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAAdV7JJ6yps",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ21zAWWv9RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import codecs\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5wfzXPL61qa",
        "colab_type": "text"
      },
      "source": [
        "#Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1V5vIL8620A",
        "colab_type": "code",
        "outputId": "4d593b74-257b-4b4e-e489-ec41a3aedce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "nltk.download('rslp')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNTv7uUd6zvx",
        "colab_type": "text"
      },
      "source": [
        "##Loads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjgT7c9fv2oh",
        "colab_type": "code",
        "outputId": "9a7972b7-7bb4-4e11-e53d-99e8c0ed7819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "files_true = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/Artigos Originais/*.txt\")):\n",
        "  try:\n",
        "    print(file)\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"utf-8\")\n",
        "    files_true.append(tfh.readlines())\n",
        "  except:\n",
        "    print(\"Erro ao ler tentando outro encoding\")\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"ISO-8859-1\")\n",
        "    files_true.append(tfh.readlines())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Artigos Originais/Artigo 1.txt\n",
            "Erro ao ler tentando outro encoding\n",
            "/content/Artigos Originais/Artigo 11.txt\n",
            "/content/Artigos Originais/Artigo 12.txt\n",
            "/content/Artigos Originais/Artigo 13.txt\n",
            "/content/Artigos Originais/Artigo 14.txt\n",
            "/content/Artigos Originais/Artigo 16.txt\n",
            "/content/Artigos Originais/Artigo 2.txt\n",
            "/content/Artigos Originais/Artigo 3.txt\n",
            "/content/Artigos Originais/Artigo 4.txt\n",
            "/content/Artigos Originais/Artigo 5.txt\n",
            "/content/Artigos Originais/Artigo 6.txt\n",
            "/content/Artigos Originais/Artigo 9.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwtpctIeyTQ8",
        "colab_type": "code",
        "outputId": "6adf2057-aad3-4225-cc1e-72514c569aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "files_pred = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/Artigos Modificados/*.txt\")):\n",
        "  try:\n",
        "    print(file)\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"utf-8\")\n",
        "    files_pred.append(tfh.readlines())\n",
        "  except:\n",
        "    print(\"Erro ao ler tentando outro encoding\")\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"ISO-8859-1\")\n",
        "    files_pred.append(tfh.readlines())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Artigos Modificados/Artigo 1 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 11 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 12 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 13 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 14 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 16 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 2 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 3 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 4 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 5 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 6 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 9 - Alterado.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DVZ7o_a7FFG",
        "colab_type": "text"
      },
      "source": [
        "#Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1eTS_YzW-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def clean(files):\n",
        "  clean_files = []\n",
        "  all_doc = files\n",
        "  #all_doc = ' '.join(files)\n",
        "  clean_files.append(re.sub('\\s+', ' ', all_doc))\n",
        "  one_doc = ' '.join(clean_files)\n",
        "  tokens = nltk.word_tokenize(one_doc)\n",
        "  stemming = PorterStemmer()\n",
        "  stem = [stemming.stem(word) for word in tokens]\n",
        "  stops = set(stopwords.words(\"english\"))      \n",
        "  stops_eng = set(stopwords.words(\"english\"))    \n",
        "  filtered_words = [word for word in stem if word not in stops]\n",
        "  filtered_words_1 = [word for word in filtered_words if word not in stops_eng]\n",
        "  filtered_words_only =list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]', '', x), filtered_words_1)))\n",
        "  filtered_words_only = [i for i in filtered_words_only if len(i) > 1]\n",
        "  return filtered_words_only\n",
        "\n",
        "def is_number(s):\n",
        "    \"\"\"\n",
        "\n",
        "    Verifica se a variavel é um número\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    image : int\n",
        "        The first parameter.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        Verdadeiro caso o cast ocorra. Falso caso contrário.\n",
        "    \"\"\" \n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def sugg_napas(doc):\n",
        "  seed_words = clean(doc)\n",
        "  corrected = []\n",
        "  for i in seed_words:\n",
        "    if not natas.is_correctly_spelled(i) and not is_number(i) and i:\n",
        "      sug = natas.ocr_correct_words([i])[0]\n",
        "      if sug:\n",
        "        corrected.append(sug[0])\n",
        "      else:\n",
        "        corrected.append(i)\n",
        "    elif i:\n",
        "      corrected.append(i)\n",
        "  return corrected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_9PYWfH7LCA",
        "colab_type": "text"
      },
      "source": [
        "#Main Statistics Napas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kwhI9ToYYSSO"
      },
      "source": [
        "##Loads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9a7972b7-7bb4-4e11-e53d-99e8c0ed7819",
        "id": "chr40l3VYSSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "files_true = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/Artigos Originais/*.txt\")):\n",
        "  try:\n",
        "    print(file)\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"utf-8\")\n",
        "    files_true.append(tfh.readlines())\n",
        "  except:\n",
        "    print(\"Erro ao ler tentando outro encoding\")\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"ISO-8859-1\")\n",
        "    files_true.append(tfh.readlines())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Artigos Originais/Artigo 1.txt\n",
            "Erro ao ler tentando outro encoding\n",
            "/content/Artigos Originais/Artigo 11.txt\n",
            "/content/Artigos Originais/Artigo 12.txt\n",
            "/content/Artigos Originais/Artigo 13.txt\n",
            "/content/Artigos Originais/Artigo 14.txt\n",
            "/content/Artigos Originais/Artigo 16.txt\n",
            "/content/Artigos Originais/Artigo 2.txt\n",
            "/content/Artigos Originais/Artigo 3.txt\n",
            "/content/Artigos Originais/Artigo 4.txt\n",
            "/content/Artigos Originais/Artigo 5.txt\n",
            "/content/Artigos Originais/Artigo 6.txt\n",
            "/content/Artigos Originais/Artigo 9.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6adf2057-aad3-4225-cc1e-72514c569aa0",
        "id": "-LzhTfevYSS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "files_pred = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/Artigos Modificados/*.txt\")):\n",
        "  try:\n",
        "    print(file)\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"utf-8\")\n",
        "    files_pred.append(tfh.readlines())\n",
        "  except:\n",
        "    print(\"Erro ao ler tentando outro encoding\")\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"ISO-8859-1\")\n",
        "    files_pred.append(tfh.readlines())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Artigos Modificados/Artigo 1 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 11 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 12 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 13 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 14 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 16 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 2 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 3 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 4 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 5 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 6 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 9 - Alterado.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFe2XawZ7OT5",
        "colab_type": "text"
      },
      "source": [
        "##Napas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ2kG0Jv8K5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%shell \n",
        "#!pip3 install natas\n",
        "#!python3 -m natas.download\n",
        "#!python3 - m spacy download en_core_web_md\n",
        "!python3 - m spacy download pt_core_news_sm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQPrCX7e8P8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import natas\n",
        "nlp = spacy.load('pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2a9ZgWjyckj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_score = []\n",
        "for y_true, y_predicted in list(zip(files_true, files_pred)):\n",
        "  y_true =  clean(y_true)\n",
        "  y_predicted = clean(y_predicted)\n",
        "  y_predicted = sugg_napas(y_predicted)\n",
        "  if len(y_true) < len(y_predicted):\n",
        "    y_predicted = y_predicted[:len(y_true)]\n",
        "  else:\n",
        "    y_true = y_true[:len(y_predicted)]\n",
        " \n",
        "  f_score.append(f1_score(y_true, y_predicted, average='micro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERCcw8k44VCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_score_np = np.asarray(f_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCWfF4FH4d7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.mean(f_score_np)\n",
        "median = np.median(f_score_np)\n",
        "std = np.std(f_score_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJovTzyG4l1j",
        "colab_type": "code",
        "outputId": "2bfd1a42-4a4a-40db-9de2-50b7f0263891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"F1 Score de cada documento\")\n",
        "print(\"Média {}\".format(round(mean, 3)))\n",
        "print(\"Mediana {}\".format(round(median, 3)))\n",
        "print(\"Desvio Padrão {}\".format(round(std, 3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score de cada documento\n",
            "Média 0.259\n",
            "Mediana 0.167\n",
            "Desvio Padrãão 0.247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi8R_zR_YGfW",
        "colab_type": "text"
      },
      "source": [
        "F1 Score de cada documento\n",
        "* Média 0.259\n",
        "* Mediana 0.167\n",
        "* Desvio Padrão 0.247"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn3xGDJuYjqc",
        "colab_type": "text"
      },
      "source": [
        "#Main Statistics CCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_95cM7yFYUEE"
      },
      "source": [
        "##Loads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9a7972b7-7bb4-4e11-e53d-99e8c0ed7819",
        "id": "Vx34oBJRYUEa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "files_true = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/Artigos Originais/*.txt\")):\n",
        "  try:\n",
        "    print(file)\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"utf-8\")\n",
        "    files_true.append(tfh.readlines())\n",
        "  except:\n",
        "    print(\"Erro ao ler tentando outro encoding\")\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"ISO-8859-1\")\n",
        "    files_true.append(tfh.readlines())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Artigos Originais/Artigo 1.txt\n",
            "Erro ao ler tentando outro encoding\n",
            "/content/Artigos Originais/Artigo 11.txt\n",
            "/content/Artigos Originais/Artigo 12.txt\n",
            "/content/Artigos Originais/Artigo 13.txt\n",
            "/content/Artigos Originais/Artigo 14.txt\n",
            "/content/Artigos Originais/Artigo 16.txt\n",
            "/content/Artigos Originais/Artigo 2.txt\n",
            "/content/Artigos Originais/Artigo 3.txt\n",
            "/content/Artigos Originais/Artigo 4.txt\n",
            "/content/Artigos Originais/Artigo 5.txt\n",
            "/content/Artigos Originais/Artigo 6.txt\n",
            "/content/Artigos Originais/Artigo 9.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6adf2057-aad3-4225-cc1e-72514c569aa0",
        "id": "OpRS8-QbYUEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "files_pred = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/Artigos Modificados/*.txt\")):\n",
        "  try:\n",
        "    print(file)\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"utf-8\")\n",
        "    files_pred.append(tfh.readlines())\n",
        "  except:\n",
        "    print(\"Erro ao ler tentando outro encoding\")\n",
        "    tfh = codecs.open(file, \"rb\", encoding=\"ISO-8859-1\")\n",
        "    files_pred.append(tfh.readlines())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Artigos Modificados/Artigo 1 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 11 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 12 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 13 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 14 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 16 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 2 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 3 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 4 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 5 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 6 - Alterado.txt\n",
            "/content/Artigos Modificados/Artigo 9 - Alterado.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGSLp5vuYYjB",
        "colab_type": "text"
      },
      "source": [
        "##Modified CCC "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2MGAVIFM2NJ",
        "colab_type": "text"
      },
      "source": [
        "Não teve os dados para que pudesse ser feito a análise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPtNgVoF5QR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_text(file_path):\n",
        "    text = []\n",
        "    with codecs.open(file_path, encoding=\"utf-8-sig\") as f:\n",
        "        for line in f:\n",
        "            text.append(line)\n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eb96kA_5YrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files_pred= load_text(\"/content/Rapunzel_250_test_albert_corredtec.txt\").split('\\n')\n",
        "files_true = load_text(\"/content/Rapunzel_250_original.txt\").split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hTTdYBg37Q5D",
        "outputId": "2a2c4c41-3486-42fb-c970-373d6d676fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "f_score = []\n",
        "for y_true, y_predicted in list(zip(files_true, files_pred)):\n",
        "  y_true =  clean(y_true)\n",
        "  y_predicted = clean(y_predicted)\n",
        "  print(\"++++++++++\")\n",
        "  print(y_true)\n",
        "  print(y_predicted)\n",
        "  if len(y_true) < len(y_predicted):\n",
        "    y_predicted = y_predicted[:len(y_true)]\n",
        "  else:\n",
        "    y_true = y_true[:len(y_predicted)]\n",
        " \n",
        "  f_score.append(f1_score(y_true, y_predicted, average='micro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++++++++++\n",
            "['onc', 'man', 'woman', 'long', 'vain', 'wish', 'child']\n",
            "['onc', 'man', 'woman', 'long', 'vain', 'wish', 'child']\n",
            "++++++++++\n",
            "['At', 'length', 'woman', 'hope', 'god', 'wa', 'grant', 'desir']\n",
            "['At', 'length', 'woman', 'hope', 'god', 'wa', 'grant', 'desir']\n",
            "++++++++++\n",
            "['peopl', 'littl', 'window', 'back', 'hous', 'splendid', 'garden', 'could', 'seen', 'wa', 'full', 'beauti', 'flower', 'herb']\n",
            "['peopl', 'littl', 'window', 'back', 'hous', 'splendid', 'garden', 'could', 'seen', 'wa', 'full', 'beauti', 'flower', 'herb']\n",
            "++++++++++\n",
            "['It', 'wa', 'howev', 'surround', 'high', 'wall', 'one', 'dare', 'go', 'becaus', 'belong', 'enchantress', 'great', 'power', 'wa', 'dread', 'world']\n",
            "['It', 'wa', 'howev', 'surround', 'high', 'call', 'one', 'dare', 'go', 'becaus', 'belong', 'enchantress', 'great', 'power', 'wa', 'dread', 'world']\n",
            "++++++++++\n",
            "['one', 'day', 'woman', 'wa', 'stand', 'thi', 'window', 'look', 'garden', 'saw', 'bed', 'wa', 'plant', 'beauti', 'flower', 'look', 'fresh', 'green', 'long', 'quit', 'pine', 'away', 'began', 'look', 'pale', 'miser']\n",
            "['one', 'day', 'woman', 'wa', 'stand', 'thi', 'window', 'look', 'garden', 'saw', 'bed', 'wa', 'plant', 'beauti', 'flower', 'look', 'fresh', 'green', 'long', 'quit', 'pine', 'away', 'began', 'look', 'pale', 'miser']\n",
            "++++++++++\n",
            "['husband', 'wa', 'alarm', 'ask', 'ail', 'dear', 'wife', 'Ah', 'repli', 'ca', 'nt', 'eat', 'flower', 'garden', 'behind', 'hous', 'shall', 'die']\n",
            "['husband', 'wa', 'alarm', 'ask', 'ail', 'dear', 'wife', 'na', 'repli', 'ca', 'eat', 'flower', 'garden', 'behind', 'hous', 'shall', 'die']\n",
            "++++++++++\n",
            "['man', 'love', 'thought', 'sooner', 'let', 'wife', 'die', 'bring', 'flower', 'let', 'cost', 'At', 'twilight', 'clamber', 'wall', 'garden', 'enchantress', 'hastili', 'clutch', 'hand', 'flower', 'took', 'hi', 'wife']\n",
            "['man', 'love', 'thought', 'let', 'wife', 'die', 'bring', 'flower', 'let', 'cost', 'willwil', 'At', 'twilight', 'clamber', 'wall', 'garden', 'enchantress', 'hastili', 'clutch', 'hand', 'flower', 'took', 'hi', 'wife']\n",
            "++++++++++\n",
            "['onc', 'made', 'salad', 'ate', 'greedili']\n",
            "['onc', 'made', 'salad', 'ate', 'greedili']\n",
            "++++++++++\n",
            "['It', 'tast', 'good', 'herso', 'veri', 'good', 'next', 'day', 'long', 'three', 'time', 'much', 'befor']\n",
            "['It', 'tast', 'good', 'veri', 'good', 'next', 'day', 'long', 'three', 'time', 'much', 'befor']\n",
            "++++++++++\n",
            "['If', 'wa', 'ani', 'rest', 'husband', 'must', 'onc', 'descend', 'garden']\n",
            "['If', 'wa', 'ani', 'rest', 'husband', 'must', 'onc', 'descend', 'garden']\n",
            "++++++++++\n",
            "['In', 'gloom', 'even', 'therefor', 'let', 'clamber', 'wall', 'wa', 'terribl', 'afraid', 'saw', 'enchantress', 'stand', 'befor']\n",
            "['In', 'gloom', 'even', 'therefor', 'let', 'clamber', 'wall', 'wa', 'terribl', 'afraid', 'saw', 'enchantress', 'stand', 'befor']\n",
            "++++++++++\n",
            "['dare', 'said', 'angri', 'look', 'descend', 'garden', 'steal', 'flower', 'like', 'thief', 'shall', 'suffer', 'Ah', 'answer', 'let', 'merci', 'take', 'place', 'justic', 'onli', 'made', 'mind', 'necess']\n",
            "['dare', 'said', 'angri', 'look', 'describ', 'garden', 'steal', 'flower', 'like', 'thief', 'shall', 'suffer', 'Ah', 'answer', 'let', 'merci', 'lake', 'place', 'justic', 'onli', 'made', 'mind', 'necess']\n",
            "++++++++++\n",
            "['My', 'wife', 'saw', 'flower', 'window', 'felt', 'long', 'would', 'die', 'got', 'eat']\n",
            "['My', 'wife', 'saw', 'flower', 'window', 'felt', 'long', 'would', 'die', 'got', 'eat']\n",
            "++++++++++\n",
            "['enchantress', 'allow', 'anger', 'soften', 'said', 'tf', 'case', 'say', 'allow', 'take', 'away', 'much', 'flower', 'onli', 'make', 'one', 'condit', 'must', 'give', 'child', 'wife', 'bring', 'world', 'shall', 'well', 'treat', 'care', 'like', 'mother']\n",
            "['enchantress', 'allow', 'anger', 'soften', 'said', 'art', 'case', 'say', 'allow', 'take', 'away', 'much', 'flower', 'onli', 'make', 'one', 'condit', 'must', 'give', 'child', 'wife', 'bring', 'world', 'shall', 'well', 'treat', 'care', 'like', 'mother']\n",
            "++++++++++\n",
            "['man', 'hi', 'terror', 'consent', 'everyth', 'woman', 'wa', 'brought', 'bed', 'enchantress', 'appear', 'onc', 'gave', 'child', 'name', 'rapunzel', 'took', 'away']\n",
            "['man', 'hi', 'terror', 'consent', 'everyth', 'woman', 'wa', 'brought', 'bed', 'enchantress', 'appear', 'onc', 'gave', 'child', 'name', 'rapunzel', 'took', 'away']\n",
            "++++++++++\n",
            "['rapunzel', 'grew', 'beauti', 'child', 'sun']\n",
            "['rapunzel', 'grew', 'beauti', 'child', 'sun']\n",
            "++++++++++\n",
            "['wa', 'twelv', 'year', 'old', 'enchantress', 'shut', 'tower', 'lay', 'forest', 'neither', 'stair', 'door', 'quit', 'top', 'wa', 'littl', 'window']\n",
            "['wa', 'twelv', 'year', 'old', 'enchantress', 'shut', 'tower', 'lay', 'forest', 'neither', 'stair', 'door', 'quit', 'top', 'wa', 'littl', 'window']\n",
            "++++++++++\n",
            "['enchantress', 'want', 'go', 'place', 'beneath', 'cri']\n",
            "['enchantress', 'want', 'go', 'place', 'beneath', 'river']\n",
            "++++++++++\n",
            "['rapunzel', 'rapunzel', 'let', 'hair']\n",
            "['control', 'rapunzel', 'let', 'hair']\n",
            "++++++++++\n",
            "['rapunzel', 'magnific', 'long', 'hair', 'fine', 'spun', 'gold', 'heard', 'voic', 'enchantress', 'unfasten', 'braid', 'tress', 'wound', 'round', 'one', 'hook', 'window', 'abov', 'hair', 'fell', 'twenti', 'ell', 'enchantress', 'climb']\n",
            "['rapunzel', 'magnific', 'long', 'hair', 'fine', 'spun', 'gold', 'heard', 'voic', 'enchantress', 'unfasten', 'braid', 'tress', 'wound', 'round', 'one', 'hook', 'window', 'abov', 'hair', 'fell', 'twenti', 'ell', 'enchantress', 'climb']\n",
            "++++++++++\n",
            "['year', 'two', 'came', 'pass', 'king', 'son', 'rode', 'forest', 'pass', 'tower']\n",
            "['year', 'two', 'came', 'pass', 'king', 'son', 'rode', 'forest', 'pass', 'tower']\n",
            "++++++++++\n",
            "['heard', 'song', 'wa', 'charm', 'stood', 'still', 'listen']\n",
            "['heard', 'song', 'wa', 'charm', 'stood', 'still', 'listen']\n",
            "++++++++++\n",
            "['thi', 'wa', 'rapunzel', 'solitud', 'pass', 'time', 'let', 'sweet', 'voic', 'resound']\n",
            "['thi', 'wa', 'rapunzel', 'solitud', 'pass', 'time', 'let', 'sweet', 'voic', 'resound']\n",
            "++++++++++\n",
            "['king', 'son', 'want', 'climb', 'look', 'door', 'tower', 'none', 'wa', 'found']\n",
            "['king', 'son', 'want', 'climb', 'look', 'door', 'tower', 'none', 'wa', 'found']\n",
            "++++++++++\n",
            "['He', 'rode', 'home', 'sing', 'deepli', 'touch', 'hi', 'heart', 'everi', 'day', 'went', 'forest', 'listen']\n",
            "['He', 'rode', 'home', 'sing', 'deepli', 'touch', 'hi', 'heart', 'everi', 'day', 'went', 'forest', 'listen']\n",
            "++++++++++\n",
            "['onc', 'wa', 'thu', 'stand', 'behind', 'tree', 'saw', 'enchantress', 'came', 'heard', 'cri']\n",
            "['onc', 'wa', 'thu', 'stand', 'behind', 'tree', 'saw', 'enchantress', 'came', 'heard', 'tri']\n",
            "++++++++++\n",
            "['rapunzel', 'rapunzel', 'let', 'hair']\n",
            "['rapunzel', 'rapunzel', 'let', 'hair']\n",
            "++++++++++\n",
            "['immedi', 'hair', 'fell', 'king', 'son', 'climb']\n",
            "['immedi', 'hair', 'fell', 'king', 'son', 'climb']\n",
            "++++++++++\n",
            "['At', 'first', 'rapunzel', 'wa', 'terribl', 'frighten', 'man', 'eye', 'never', 'yet', 'beheld', 'came', 'king', 'son', 'began', 'talk', 'quit', 'like', 'friend', 'told', 'hi', 'heart', 'stir', 'jet', 'rest', 'forc', 'see']\n",
            "['At', 'first', 'rapunzel', 'wa', 'terribl', 'frighten', 'man', 'eye', 'never', 'yet', 'beheld', 'came', 'king', 'son', 'began', 'talk', 'quit', 'like', 'friend', 'told', 'hi', 'heart', 'stir', 'jet', 'rest', 'forc', 'see']\n",
            "++++++++++\n",
            "['rapunzel', 'lost', 'fear', 'ask', 'would', 'take', 'husband', 'saw', 'wa', 'young', 'handsom', 'thought', 'He', 'love', 'old', 'dame', 'gothel', 'doe', 'said', 'ye', 'laid', 'hand', 'hi']\n",
            "['rapunzel', 'lost', 'fear', 'ask', 'would', 'take', 'husband', 'saw', 'wa', 'young', 'handsom', 'thought', 'He', 'love', 'old', 'dame', 'tell', 'doe', 'said', 'ye', 'laid', 'hand', 'hi']\n",
            "++++++++++\n",
            "['said', 'willingli', 'go', 'away', 'know', 'get']\n",
            "['said', 'willingli', 'go', 'away', 'know', 'get']\n",
            "++++++++++\n",
            "['bring', 'skein', 'silk', 'everi', 'time', 'come', 'weav', 'ladder', 'readi', 'descend', 'take', 'hors']\n",
            "['bring', 'skein', 'silk', 'everi', 'time', 'come', 'weav', 'ladder', 'readi', 'descend', 'take', 'hors']\n",
            "++++++++++\n",
            "['agre', 'time', 'come', 'everi', 'even', 'old', 'woman', 'came', 'day']\n",
            "['agre', 'time', 'come', 'everi', 'even', 'old', 'woman', 'came', 'day']\n",
            "++++++++++\n",
            "['enchantress', 'remark', 'noth', 'thi', 'onc', 'rapunzel', 'said', 'tell', 'dame', 'gothel', 'happen', 'much', 'heavier', 'draw', 'young', 'king', 'sonh', 'moment']\n",
            "['enchantress', 'remark', 'noth', 'thi', 'onc', 'rapunzel', 'said', 'tell', 'dame', 'tell', 'happen', 'much', 'heavier', 'draw', 'young', 'king', 'son', 'moment']\n",
            "++++++++++\n",
            "['Ah', 'wick', 'child', 'cri', 'enchantress']\n",
            "['na', 'wick', 'child', 'cri', 'enchantress']\n",
            "++++++++++\n",
            "['hear', 'say', 'thought', 'separ', 'world', 'yet', 'deceiv', 'In', 'anger', 'clutch', 'rapunzel', 'beauti', 'tress', 'wrap', 'twice', 'round', 'left', 'hand', 'seiz', 'pair', 'scissor', 'right', 'snip', 'snap', 'cut', 'love', 'braid', 'lay', 'ground']\n",
            "['hear', 'say', 'thought', 'separ', 'world', 'yet', 'deceiv', 'men', 'In', 'anger', 'clutch', 'rapunzel', 'beauti', 'tress', 'wrap', 'twice', 'round', 'left', 'hand', 'seiz', 'pair', 'scissor', 'right', 'snip', 'snap', 'cut', 'love', 'braid', 'lay', 'ground']\n",
            "++++++++++\n",
            "['wa', 'pitiless', 'took', 'poor', 'rapunzel', 'desert', 'live', 'great', 'grief', 'miseri']\n",
            "['wa', 'pitiless', 'took', 'poor', 'rapunzel', 'desert', 'live', 'great', 'grief', 'miseri']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AsJBFPMW7Q5Y",
        "colab": {}
      },
      "source": [
        "f_score_np = np.asarray(f_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "he8dwNwR7Q5e",
        "colab": {}
      },
      "source": [
        "mean = np.mean(f_score_np)\n",
        "median = np.median(f_score_np)\n",
        "std = np.std(f_score_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4_qfqVbF7Q5l",
        "outputId": "c26117a2-4dd6-4461-bf9b-6c192ce4000a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"F1 Score de cada documento\")\n",
        "print(\"Média {}\".format(round(mean, 3)))\n",
        "print(\"Mediana {}\".format(round(median, 3)))\n",
        "print(\"Desvio Padrão {}\".format(round(std, 3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score de cada documento\n",
            "Média 0.909\n",
            "Mediana 1.0\n",
            "Desvio Padrão 0.19\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}